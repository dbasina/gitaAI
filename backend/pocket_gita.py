import elasticsearch, openai, json, urllib3
from elasticsearch import Elasticsearch, helpers
from openai import OpenAI
from sentence_transformers import SentenceTransformer

# Disable security warnings temporarily.
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

#  Database keys and index
ELASTIC_CLOUD_ID = "My_deployment:dXMtY2VudHJhbDEuZ2NwLmNsb3VkLmVzLmlvJDA2NzRmYzY4NTBmNjRjNzBhZDgyNjI0MTVmMzYxM2I5JGE0ODIyZTVkYTVlMjRmNTliYTQyODVlZWI1YjJlNzIz"
ELASTIC_API_KEY = "R1FGdlZwTUJtLV9GRml5dlR4bmQ6cmxQSWVSUTBTUHF0QldmRjRYbk91Zw=="
index = "gita_english_semantic"

# OpenAI key
openai.api_key= "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"

# es instance
es = Elasticsearch(
    # For local development
    cloud_id=ELASTIC_CLOUD_ID,
    api_key=ELASTIC_API_KEY,
)


# Load the SentenceTransformer model
model = SentenceTransformer("all-MiniLM-L6-v2")

def generate_embedding(text):
    """Generate embeddings using the SentenceTransformer model."""
    return model.encode(text, convert_to_numpy=True).tolist()

def vector_search(es, index, query, top_k=5):
    """Perform a vector search in Elasticsearch."""
    embedding = generate_embedding(query)
    search_query = {
        "size": top_k,
        "_source": ["authorName", "verseNumber", "description"],
        "query": {
            "script_score": {
                "query": {"match_all": {}},
                "script": {
                    "source": "cosineSimilarity(params.query_vector, 'embedding') + 1.0",
                    "params": {"query_vector": embedding}
                }
            }
        }
    }
    response = es.search(index=index, body=search_query)
    return response["hits"]["hits"]

def format_results_for_gpt(results):
    """Format Elasticsearch results for GPT."""
    formatted = "Relevant verses from the Gita:\n\n"
    for i, result in enumerate(results, start=1):
        source = result["_source"]
        formatted += f"{i}. {source['authorName']}:\n"
        formatted += f"   \"{source['description']}\"\n\n"
    return formatted

def send_to_gpt(prompt):
    """Send formatted results to OpenAI's GPT for summarization."""
    system_prompt =f"""You are a motivational speaker that offers spiritual guidance.
                      - You are given a spiritual leader's insights from the Gita.
                      - assume that the verses given to you were generated by yourself after reading the Gita
                      - The user came to you to seek spiritual guidance
                      - determine the verses that are highly relevant to the user's scenario
                      - using these verses as inspiration, interpret them and write an inspiring message to the user about what gita has to say about their situation,
                      
                      """
    try:
        response = openai.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=500
        )
        return response.choices[0].message.content
    except Exception as e:
        print(f"Error with GPT API: {e}")
        return None

if __name__ == "__main__":
    # Example Query
    while True:
        #query = "What is the essence of duty in Gita?"
        #query = "I have faced a lot of failures in my life and I am feeling low."
        #query = "I am not having any fun and im not making any progress in mythic plus in world of warcraft. What do I do? what does gita advice?"
        query = input('enter your soul redeeming question:\n')
        # Step 1: Perform Semantic Search
        print("GPT is processing")
        search_results = vector_search(es, index, query, top_k=30)

        # Step 2: Format Results for GPT
        formatted_results = format_results_for_gpt(search_results)
        # print("Formatted Results:\n", formatted_results)

        # Step 3: Send to GPT for Interpretation
        # print("Sending results to GPT for summarization...")
        human_readable_output = send_to_gpt(formatted_results)

        # Step 4: Display GPT's Response
        print("\nGPT's Response:\n", human_readable_output)